2020-10-22 20:56:29,049 ----------------------------------------------------------------------------------------------------
2020-10-22 20:56:29,049 Model: "FastSequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): FastCharacterEmbeddings(
      (char_embedding): Embedding(88, 25)
      (char_drop): Dropout(p=0.5, inplace=False)
      (char_layer): Conv1d(25, 25, kernel_size=(3,), stride=(1,), padding=(1,))
    )
    (list_embedding_1): FastWordEmbeddings(
      (word_embedding): Embedding(28754, 100)
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (rnn): LSTM(125, 256, bidirectional=True)
  (linear): Linear(in_features=512, out_features=20, bias=True)
  (mfvi): MFVI()
)"
2020-10-22 20:56:29,049 ----------------------------------------------------------------------------------------------------
2020-10-22 20:56:29,049 Corpus: "Corpus: 14039 train + 3246 dev + 3453 test sentences"
2020-10-22 20:56:29,050 ----------------------------------------------------------------------------------------------------
2020-10-22 20:56:29,050 Parameters:
2020-10-22 20:56:29,050  - Optimizer: "SGD"
2020-10-22 20:56:29,050  - learning_rate: "0.1"
2020-10-22 20:56:29,050  - mini_batch_size: "32"
2020-10-22 20:56:29,050  - patience: "10"
2020-10-22 20:56:29,050  - anneal_factor: "0.5"
2020-10-22 20:56:29,050  - max_epochs: "300"
2020-10-22 20:56:29,050  - shuffle: "True"
2020-10-22 20:56:29,050  - train_with_dev: "False"
2020-10-22 20:56:29,050  - word min_freq: "-1"
2020-10-22 20:56:29,050 ----------------------------------------------------------------------------------------------------
2020-10-22 20:56:29,050 Model training base path: "resources/taggers/3iter_word_char_charcnn_300epoch_32batch_0.1lr_1window_256hidden_en_lample_monolingual_mfvi_sentloss_10patience_baseline_fast_2nd_startend_sentbatch_norelearn_nodev_ner35"
2020-10-22 20:56:29,050 ----------------------------------------------------------------------------------------------------
2020-10-22 20:56:29,050 Device: cuda:0
2020-10-22 20:56:29,050 ----------------------------------------------------------------------------------------------------
2020-10-22 20:56:29,050 Embeddings storage mode: cpu
2020-10-22 20:56:31,705 Finished Embeddings Assignments
2020-10-22 20:56:31,706 ----------------------------------------------------------------------------------------------------
2020-10-22 20:56:31,706 Current loss interpolation: 1
2020-10-22 20:56:32,097 epoch 1 - iter 0/439 - loss 67.75917053 - samples/sec: 81.99 - decode_sents/sec: 88.49
2020-10-22 20:56:33,472 epoch 1 - iter 43/439 - loss 15.60226778 - samples/sec: 1000.56 - decode_sents/sec: 118874.61
2020-10-22 20:56:34,783 epoch 1 - iter 86/439 - loss 13.44770377 - samples/sec: 1050.31 - decode_sents/sec: 132340.34
2020-10-22 20:56:36,112 epoch 1 - iter 129/439 - loss 11.83566747 - samples/sec: 1036.23 - decode_sents/sec: 189429.95
2020-10-22 20:56:37,573 epoch 1 - iter 172/439 - loss 11.19999703 - samples/sec: 942.34 - decode_sents/sec: 160677.14
2020-10-22 20:56:38,991 epoch 1 - iter 215/439 - loss 10.16134650 - samples/sec: 970.92 - decode_sents/sec: 150092.64
2020-10-22 20:56:40,412 epoch 1 - iter 258/439 - loss 9.54018661 - samples/sec: 968.91 - decode_sents/sec: 138668.00
2020-10-22 20:56:41,844 epoch 1 - iter 301/439 - loss 8.92127872 - samples/sec: 961.22 - decode_sents/sec: 130420.37
2020-10-22 20:56:43,282 epoch 1 - iter 344/439 - loss 8.55095284 - samples/sec: 957.97 - decode_sents/sec: 128718.74
2020-10-22 20:56:44,675 epoch 1 - iter 387/439 - loss 8.20142117 - samples/sec: 981.64 - decode_sents/sec: 134623.47
2020-10-22 20:56:46,076 epoch 1 - iter 430/439 - loss 7.88927281 - samples/sec: 983.12 - decode_sents/sec: 177585.84
2020-10-22 20:56:46,341 ----------------------------------------------------------------------------------------------------
2020-10-22 20:56:46,341 EPOCH 1 done: loss 7.8184 - lr 0.1
2020-10-22 20:56:46,342 ----------------------------------------------------------------------------------------------------
2020-10-22 20:56:48,638 Macro Average: 72.36	Macro avg loss: 3.74
CONLL_03	72.36	
2020-10-22 20:56:48,686 ----------------------------------------------------------------------------------------------------
2020-10-22 20:56:48,686 BAD EPOCHS (no improvement): 0
2020-10-22 20:56:48,686 GLOBAL BAD EPOCHS (no improvement): 0
2020-10-22 20:56:48,686 ==================Saving the current best model: 72.36==================
2020-10-22 20:56:48,783 ----------------------------------------------------------------------------------------------------
2020-10-22 20:56:48,784 Current loss interpolation: 1
2020-10-22 20:56:48,815 epoch 2 - iter 0/439 - loss 1.99479175 - samples/sec: 1038.03 - decode_sents/sec: 3379.10
2020-10-22 20:56:50,232 epoch 2 - iter 43/439 - loss 4.90309349 - samples/sec: 971.76 - decode_sents/sec: 130780.93
2020-10-22 20:56:51,679 epoch 2 - iter 86/439 - loss 4.81089972 - samples/sec: 951.27 - decode_sents/sec: 384578.02
2020-10-22 20:56:53,106 epoch 2 - iter 129/439 - loss 4.57730471 - samples/sec: 964.46 - decode_sents/sec: 127934.08
2020-10-22 20:56:54,371 epoch 2 - iter 172/439 - loss 4.59124430 - samples/sec: 1088.50 - decode_sents/sec: 127840.56
2020-10-22 20:56:55,741 epoch 2 - iter 215/439 - loss 4.51623895 - samples/sec: 1004.89 - decode_sents/sec: 177329.39
2020-10-22 20:56:57,183 epoch 2 - iter 258/439 - loss 4.33310984 - samples/sec: 955.12 - decode_sents/sec: 175325.42
2020-10-22 20:56:58,640 epoch 2 - iter 301/439 - loss 4.28965516 - samples/sec: 938.56 - decode_sents/sec: 219401.28
2020-10-22 20:56:59,943 epoch 2 - iter 344/439 - loss 4.22624326 - samples/sec: 1057.30 - decode_sents/sec: 136213.41
2020-10-22 20:57:01,402 epoch 2 - iter 387/439 - loss 4.18230193 - samples/sec: 943.60 - decode_sents/sec: 139857.57
2020-10-22 20:57:02,795 epoch 2 - iter 430/439 - loss 4.11301052 - samples/sec: 988.83 - decode_sents/sec: 117478.42
2020-10-22 20:57:03,073 ----------------------------------------------------------------------------------------------------
2020-10-22 20:57:03,073 EPOCH 2 done: loss 4.0932 - lr 0.1
2020-10-22 20:57:03,073 ----------------------------------------------------------------------------------------------------
2020-10-22 20:57:05,295 Macro Average: 80.98	Macro avg loss: 2.44
CONLL_03	80.98	
2020-10-22 20:57:05,345 ----------------------------------------------------------------------------------------------------
2020-10-22 20:57:05,345 BAD EPOCHS (no improvement): 0
2020-10-22 20:57:05,345 GLOBAL BAD EPOCHS (no improvement): 0
2020-10-22 20:57:05,345 ==================Saving the current best model: 80.97999999999999==================
2020-10-22 20:57:05,430 ----------------------------------------------------------------------------------------------------
2020-10-22 20:57:05,430 Current loss interpolation: 1
2020-10-22 20:57:05,455 epoch 3 - iter 0/439 - loss 3.67457628 - samples/sec: 1290.87 - decode_sents/sec: 7278.22
2020-10-22 20:57:06,664 epoch 3 - iter 43/439 - loss 3.18134844 - samples/sec: 1139.19 - decode_sents/sec: 128730.23
2020-10-22 20:57:08,048 epoch 3 - iter 86/439 - loss 3.33090944 - samples/sec: 988.12 - decode_sents/sec: 177319.11
2020-10-22 20:57:09,471 epoch 3 - iter 129/439 - loss 3.42246888 - samples/sec: 967.49 - decode_sents/sec: 137018.64
2020-10-22 20:57:10,945 epoch 3 - iter 172/439 - loss 3.39174917 - samples/sec: 933.93 - decode_sents/sec: 138021.34
2020-10-22 20:57:12,381 epoch 3 - iter 215/439 - loss 3.49726736 - samples/sec: 958.99 - decode_sents/sec: 327862.43
2020-10-22 20:57:13,456 epoch 3 - iter 258/439 - loss 3.47919005 - samples/sec: 1280.61 - decode_sents/sec: 227649.19
2020-10-22 20:57:14,816 epoch 3 - iter 301/439 - loss 3.50482360 - samples/sec: 1012.17 - decode_sents/sec: 240073.31
2020-10-22 20:57:16,202 ----------------------------------------------------------------------------------------------------
2020-10-22 20:57:16,203 Exiting from training early.
2020-10-22 20:57:16,203 Saving model ...
2020-10-22 20:57:16,285 Done.
2020-10-22 20:57:16,286 ----------------------------------------------------------------------------------------------------
2020-10-22 20:57:16,286 loading file resources/taggers/3iter_word_char_charcnn_300epoch_32batch_0.1lr_1window_256hidden_en_lample_monolingual_mfvi_sentloss_10patience_baseline_fast_2nd_startend_sentbatch_norelearn_nodev_ner35/best-model.pt
2020-10-22 20:57:16,313 Testing using best model ...
2020-10-22 20:57:16,799 Finished Embeddings Assignments
2020-10-22 20:57:18,997 0.8349	0.779	0.806
2020-10-22 20:57:18,997 
MICRO_AVG: acc 0.6751 - f1-score 0.806
MACRO_AVG: acc 0.6581 - f1-score 0.789025
LOC        tp: 1330 - fp: 139 - fn: 338 - tn: 1330 - precision: 0.9054 - recall: 0.7974 - accuracy: 0.7360 - f1-score: 0.8480
MISC       tp: 413 - fp: 95 - fn: 289 - tn: 413 - precision: 0.8130 - recall: 0.5883 - accuracy: 0.5182 - f1-score: 0.6826
ORG        tp: 1316 - fp: 526 - fn: 345 - tn: 1316 - precision: 0.7144 - recall: 0.7923 - accuracy: 0.6017 - f1-score: 0.7513
PER        tp: 1341 - fp: 110 - fn: 276 - tn: 1341 - precision: 0.9242 - recall: 0.8293 - accuracy: 0.7765 - f1-score: 0.8742
2020-10-22 20:57:18,997 ----------------------------------------------------------------------------------------------------
2020-10-22 20:57:18,997 ----------------------------------------------------------------------------------------------------
2020-10-22 20:57:18,997 current corpus: CONLL_03
2020-10-22 20:57:19,391 Finished Embeddings Assignments
2020-10-22 20:57:21,662 0.8349	0.779	0.806
2020-10-22 20:57:21,662 
MICRO_AVG: acc 0.6751 - f1-score 0.806
MACRO_AVG: acc 0.6581 - f1-score 0.789025
LOC        tp: 1330 - fp: 139 - fn: 338 - tn: 1330 - precision: 0.9054 - recall: 0.7974 - accuracy: 0.7360 - f1-score: 0.8480
MISC       tp: 413 - fp: 95 - fn: 289 - tn: 413 - precision: 0.8130 - recall: 0.5883 - accuracy: 0.5182 - f1-score: 0.6826
ORG        tp: 1316 - fp: 526 - fn: 345 - tn: 1316 - precision: 0.7144 - recall: 0.7923 - accuracy: 0.6017 - f1-score: 0.7513
PER        tp: 1341 - fp: 110 - fn: 276 - tn: 1341 - precision: 0.9242 - recall: 0.8293 - accuracy: 0.7765 - f1-score: 0.8742
