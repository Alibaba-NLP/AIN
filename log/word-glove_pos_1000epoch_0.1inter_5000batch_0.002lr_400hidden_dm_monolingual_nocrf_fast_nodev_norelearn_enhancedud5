/home/wangxy/anaconda3/envs/parser/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/wangxy/anaconda3/envs/parser/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/wangxy/anaconda3/envs/parser/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/wangxy/anaconda3/envs/parser/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/wangxy/anaconda3/envs/parser/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/wangxy/anaconda3/envs/parser/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/wangxy/anaconda3/envs/parser/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/wangxy/anaconda3/envs/parser/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/wangxy/anaconda3/envs/parser/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/wangxy/anaconda3/envs/parser/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/wangxy/anaconda3/envs/parser/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/wangxy/anaconda3/envs/parser/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/wangxy/workspace/flair2/flair/utils/params.py:104: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  dict_merge.dict_merge(params_dict, yaml.load(f))
2020-09-03 18:09:18,260 Reading data from /home/wangxy/.flair/datasets/enhanced_ud/DM
2020-09-03 18:09:18,260 Train: /home/wangxy/.flair/datasets/enhanced_ud/DM/train.en.dm_modified.conllu
2020-09-03 18:09:18,261 Test: /home/wangxy/.flair/datasets/enhanced_ud/DM/test.en.id.dm.conllu
2020-09-03 18:09:18,261 Dev: /home/wangxy/.flair/datasets/enhanced_ud/DM/dev.en.dm.conllu
2020-09-03 18:09:39,867 Reading data from /home/wangxy/.flair/datasets/enhanced_ud/DM_OOD
2020-09-03 18:09:39,867 Train: /home/wangxy/.flair/datasets/enhanced_ud/DM_OOD/train.conllu
2020-09-03 18:09:39,867 Test: /home/wangxy/.flair/datasets/enhanced_ud/DM_OOD/test.en.ood.dm.conllu
2020-09-03 18:09:39,867 Dev: /home/wangxy/.flair/datasets/enhanced_ud/DM_OOD/dev.conllu
2020-09-03 18:09:45,755 {b'<unk>': 0, b'O': 1, b'root': 2, b'': 3, b'compound': 4, b'ARG1': 5, b'measure': 6, b'loc': 7, b'ARG2': 8, b'BV': 9, b'of': 10, b'appos': 11, b'ARG3': 12, b'mwe': 13, b'poss': 14, b'_nor_c': 15, b'_and_c': 16, b'times': 17, b'than': 18, b'part': 19, b'subord': 20, b'conj': 21, b'comp': 22, b'neg': 23, b'_or_c': 24, b'_but_c': 25, b'comp_so': 26, b'comp_less': 27, b'plus': 28, b'ARG4': 29, b'_rather+than_c': 30, b'_as+well+as_c': 31, b'comp_enough': 32, b'temp': 33, b'discourse': 34, b'comp_too': 35, b'parenthetical': 36, b'_but+not_c': 37, b'_and+so_c': 38, b'_but+also_c': 39, b'_not_c': 40, b'_then_c': 41, b'manner': 42, b'_and+also_c': 43, b'_except_c': 44, b'_and+then_c': 45, b'_and+not_c': 46, b'_yet_c': 47, b'_versus_c': 48, b'_even_c': 49, b'_instead+of_c': 50, b'_plus_c': 51, b'_and+thus_c': 52, b'_minus_c': 53, b'_and+yet_c': 54, b'_after_c': 55, b'_if+not_c': 56, b'_not+to+mention_c': 57, b'_though_c': 58, b'comp_not+so': 59, b'_much+less_c': 60, b'_formerly_c': 61, b'_except+that_c': 62, b'comp_not+too': 63, b'<START>': 64, b'<STOP>': 65}
2020-09-03 18:09:45,755 Corpus: 33916 train + 1692 dev + 3259 test sentences
[2020-09-03 18:09:45,756 INFO] loading Word2VecKeyedVectors object from /home/wangxy/.flair/embeddings/glove.gensim
[2020-09-03 18:09:46,381 INFO] loading vectors from /home/wangxy/.flair/embeddings/glove.gensim.vectors.npy with mmap=None
[2020-09-03 18:09:46,458 INFO] setting ignored attribute vectors_norm to None
[2020-09-03 18:09:46,458 INFO] loaded /home/wangxy/.flair/embeddings/glove.gensim
Corpus: 33916 train + 1692 dev + 3259 test sentences
2020-09-03 18:09:51,985 ----------------------------------------------------------------------------------------------------
2020-09-03 18:09:51,986 Model: "SemanticDependencyParser(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): FastWordEmbeddings(
      (word_embedding): Embedding(22389, 100)
    )
    (list_embedding_1): POSEmbeddings(
      (pos_embedding): Embedding(47, 50)
    )
  )
  (word_dropout): WordDropout(p=0.33)
  (locked_dropout): LockedDropout(p=0.5)
  (embed_dropout): IndependentDropout(p=0.33)
  (rnn): BiLSTM(150, 400, num_layers=3, dropout=0.33)
  (lstm_dropout_func): SharedDropout(p=0.33, batch_first=True)
  (mlp_arc_h): MLP(
    (linear): Linear(in_features=800, out_features=500, bias=True)
    (activation): LeakyReLU(negative_slope=0.1)
    (dropout): SharedDropout(p=0.33, batch_first=True)
  )
  (mlp_arc_d): MLP(
    (linear): Linear(in_features=800, out_features=500, bias=True)
    (activation): LeakyReLU(negative_slope=0.1)
    (dropout): SharedDropout(p=0.33, batch_first=True)
  )
  (mlp_rel_h): MLP(
    (linear): Linear(in_features=800, out_features=100, bias=True)
    (activation): LeakyReLU(negative_slope=0.1)
    (dropout): SharedDropout(p=0.33, batch_first=True)
  )
  (mlp_rel_d): MLP(
    (linear): Linear(in_features=800, out_features=100, bias=True)
    (activation): LeakyReLU(negative_slope=0.1)
    (dropout): SharedDropout(p=0.33, batch_first=True)
  )
  (arc_attn): Biaffine(n_in=500, n_out=1, bias_x=True)
  (rel_attn): Biaffine(n_in=100, n_out=66, bias_x=True, bias_y=True)
  (rel_criterion): CrossEntropyLoss()
  (arc_criterion): BCEWithLogitsLoss()
)"
2020-09-03 18:09:51,986 ----------------------------------------------------------------------------------------------------
2020-09-03 18:09:51,986 Corpus: "Corpus: 33916 train + 1692 dev + 3259 test sentences"
2020-09-03 18:09:51,986 ----------------------------------------------------------------------------------------------------
2020-09-03 18:09:51,986 Parameters:
2020-09-03 18:09:51,986  - Optimizer: "Adam"
2020-09-03 18:09:51,986  - learning_rate: "0.002"
2020-09-03 18:09:51,986  - mini_batch_size: "5000"
2020-09-03 18:09:51,987  - patience: "10"
2020-09-03 18:09:51,987  - anneal_factor: "0.5"
2020-09-03 18:09:51,987  - max_epochs: "1000"
2020-09-03 18:09:51,987  - shuffle: "True"
2020-09-03 18:09:51,987  - train_with_dev: "False"
2020-09-03 18:09:51,987  - word min_freq: "2"
2020-09-03 18:09:51,987 ----------------------------------------------------------------------------------------------------
2020-09-03 18:09:51,987 Model training base path: "resources/taggers/word-glove_pos_1000epoch_0.1inter_5000batch_0.002lr_400hidden_dm_monolingual_nocrf_fast_nodev_norelearn_enhancedud5"
2020-09-03 18:09:51,987 ----------------------------------------------------------------------------------------------------
2020-09-03 18:09:51,987 Device: cuda:0
2020-09-03 18:09:51,987 ----------------------------------------------------------------------------------------------------
2020-09-03 18:09:51,987 Embeddings storage mode: cpu
2020-09-03 18:10:16,418 Finished Embeddings Assignments
2020-09-03 18:10:16,418 ----------------------------------------------------------------------------------------------------
2020-09-03 18:10:16,418 Current loss interpolation: 1
['Word: glove', 'pos']
2020-09-03 18:10:18,493 epoch 1 - iter 0/160 - loss 2.08559585 - samples/sec: 77.61
